{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 643971,
          "sourceType": "datasetVersion",
          "datasetId": 319080,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "SkinCancerDetectionUsingVGG16Arch",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishan1923/Skin-Cancer-Detection-using-DL-techniques/blob/main/SkinCancerDetectionUsingVGG16Arch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "nodoubttome_skin_cancer9_classesisic_path = kagglehub.dataset_download('nodoubttome/skin-cancer9-classesisic')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "fNbvDvgC4F5z"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "4NfhYzDq4F6I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from keras import layers\n",
        "from tensorflow import data as tf_data"
      ],
      "metadata": {
        "trusted": true,
        "id": "6IgzBuqa4F6O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "trusted": true,
        "id": "4RuZuZL24F6T"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU available: \", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "fLob-vQK4F6V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download the dataset\n",
        "dataset_path = kagglehub.dataset_download(\"nodoubttome/skin-cancer9-classesisic\")\n",
        "\n",
        "print(\"Path to dataset files:\", dataset_path)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JAB6kZYD4F6X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"current directory contents: \\n\", os.listdir(dataset_path))"
      ],
      "metadata": {
        "trusted": true,
        "id": "yFx9Hypk4F6Z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ISIC_folder = os.path.join(dataset_path, os.listdir(dataset_path)[0])\n",
        "print(ISIC_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "94t6uO1_4F6d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(ISIC_folder))"
      ],
      "metadata": {
        "trusted": true,
        "id": "dTfULsxX4F6f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_folder = os.path.join(ISIC_folder, os.listdir(ISIC_folder)[0])\n",
        "print(train_image_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YkxDKGrG4F6j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(train_image_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "WWBqrilh4F6l"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_folder = os.path.join(ISIC_folder, os.listdir(ISIC_folder)[0])\n",
        "print(test_image_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "5ZweTKNJ4F6n"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(train_image_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "uRs2SOaW4F6p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(test_image_folder)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DTECy5254F6r"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_images_address = []\n",
        "train_images_labels = []\n",
        "test_images_address = []\n",
        "test_images_labels = []\n",
        "\n",
        "count = 0\n",
        "for folder in os.listdir(train_image_folder):\n",
        "    folder_path = os.path.join(train_image_folder, folder)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        train_images_address.append(file_path)\n",
        "        train_images_labels.append(count)\n",
        "    count = count + 1\n",
        "\n",
        "count = 0\n",
        "for folder in os.listdir(test_image_folder):\n",
        "    folder_path = os.path.join(test_image_folder, folder)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        test_images_address.append(file_path)\n",
        "        test_images_labels.append(count)\n",
        "    count = count + 1\n",
        "\n",
        "print(\"total classes in training folder: \", len(train_images_address))\n",
        "print(\"total classes in test folder: \", len(test_images_address))\n",
        "print(\"total training images: \",len(train_images_labels))\n",
        "print(\"total test images\", len(test_images_labels))\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "a_zkyyVD4F6u"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class TFPreprocessingPipiline:\n",
        "  def __init__(self, img_size = (224,224), batch_size = 32):\n",
        "    self.img_size = img_size\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def preprocess_image(self, image_path, label):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_image(image, channels = 3)\n",
        "    image = tf.reshape(image, [tf.shape(image)[0], tf.shape(image)[1], 3])\n",
        "    image = tf.image.resize(image, self.img_size)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "  def preprocess_with_augmentation(self, image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta = 0.2)\n",
        "    image = tf.image.random_contrast(image, lower = 0.8, upper = 1.2)\n",
        "    image = tf.image.random_contrast(image, lower = 0.8, upper = 1.2)\n",
        "\n",
        "\n",
        "    k = tf.random.uniform([], 0, 4, tf.int32)\n",
        "    image = tf.image.rot90(image, k)\n",
        "\n",
        "    image = tf.clip_by_value(image, 0, 1)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  def create_dataset_from_directory(self, data_dir, validation_split = 0.2, subset = 'training', augment = True):\n",
        "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "        data_dir,\n",
        "        validation_split = validation_split,\n",
        "        subset = subset,\n",
        "        seed = 42,\n",
        "        image_size = self.img_size,\n",
        "        batch_size = self.batch_size,\n",
        "        label_mode = 'categorical'\n",
        "    )\n",
        "\n",
        "    if augment and subset == 'training':\n",
        "      dataset = dataset.map(self.apply_augmentation_to_batch, num_paraller_calls = tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y), num_parallel_calls = tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  def apply_augmentation_to_batch(self, images, labels):\n",
        "    augmented_images = tf.map_fn(\n",
        "        lambda img: self.augment_single_image(img),\n",
        "        images,\n",
        "        parallel_iterations = 10,\n",
        "        dtype = tf.float32\n",
        "    )\n",
        "    return augmented_images, labels\n",
        "\n",
        "  def augment_single_images(self, images):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image\n",
        "\n",
        "  def create_dataset_from_paths_and_labels(self, image_paths, labels, augment = True):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "\n",
        "    dataset = dataset.map(self.preprocess_image, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "\n",
        "    if augment :\n",
        "      dataset = dataset.map(self.preprocess_with_augmentation, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "    else:\n",
        "      dataset = dataset.map(self.preprocess_image, num_parallel_calls = tf.data.AUTOTUNE)\n",
        "\n",
        "    dataset = dataset.shuffle(buffer_size = 1000)\n",
        "    dataset = dataset.batch(self.batch_size)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  def create_dataset_for_prediction(self, image_paths):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    dataset = dataset.map(\n",
        "        lambda path : self.preprocess_image_only(path),\n",
        "        num_parallel_calls = tf.data.AUTOTUNE\n",
        "        )\n",
        "\n",
        "    dataset = dataset.batch(self.batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "  def preprocess_image_only(self, image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_image(image, channels = 3)\n",
        "    image = tf.reshape(image, [tf.shape(image)[0], tf.shape(image)[1], 3])\n",
        "    image = tf.image.resize(image, self.img_size)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "  def visualize_batch(self, dataset, num_images = 9):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    for images in dataset.take(1):\n",
        "      fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
        "      ax = ax.ravel()\n",
        "\n",
        "      for i in range(min(num_images, len(images))):\n",
        "        img = images[i].numpy()\n",
        "        ax[i].imshow(img)\n",
        "        ax[i].axis('off')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "      break\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "aZhlqRxO4F6v"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing_pipeline = PreprocessingTrainingData()\n",
        "# training_dataset = preprocessing_pipeline.create_dataset(train_images_address, train_images_labels)\n",
        "# test_dataset = preprocessing_pipeline.create_dataset_for_prediction(test_images_address)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MEvGcTAP4F85"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# training_dataset.take(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "n3cr_JZf4F86"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing_pipeline.visualize_batch(training_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nyvqstHk4F87"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_images_address), len(train_images_labels))"
      ],
      "metadata": {
        "trusted": true,
        "id": "cSXaJ4_R4F87"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_images_address), len(test_images_labels))"
      ],
      "metadata": {
        "trusted": true,
        "id": "2caLDKle4F88"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {
        "id": "_g1cae8A4F89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = TFPreprocessingPipiline(img_size=(224, 224), batch_size = 32)\n",
        "\n",
        "train_dataset = pipeline.create_dataset_from_paths_and_labels(train_images_address, train_images_labels)\n",
        "\n",
        "print(f\"dataset: {train_dataset}\")\n",
        "\n",
        "test_dataset = pipeline.create_dataset_from_paths_and_labels(test_images_address, test_images_labels)\n",
        "t_dataset = pipeline.create_dataset_for_prediction(test_images_address)\n",
        "print(f\"dataset: {test_dataset}\")\n",
        "\n",
        "train_dataset.take(1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "OR940XtM4F89"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.visualize_batch(t_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "O06Hpw6L4F8-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the VGG16 Architecture Model"
      ],
      "metadata": {
        "id": "otKn57Wj4F8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # Rescaling layer\n",
        "    x = keras.layers.Rescaling(scale=1.0 / 255.0)(inputs)\n",
        "\n",
        "    # First conv block\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=2\n",
        "    )(x)\n",
        "\n",
        "    # Second conv block\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=2\n",
        "    )(x)\n",
        "\n",
        "    # Third conv block\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=256,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=2\n",
        "    )(x)\n",
        "\n",
        "    # Fourth conv block\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=512,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=512,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Conv2D(\n",
        "        filters=512,\n",
        "        kernel_size=(3, 3),\n",
        "        padding=\"same\",\n",
        "        strides=1,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.MaxPooling2D(\n",
        "        pool_size=(2, 2),\n",
        "        strides=2\n",
        "    )(x)\n",
        "\n",
        "    # Flatten before dense layers\n",
        "    x = keras.layers.Flatten()(x)\n",
        "\n",
        "    # Fully connected layers\n",
        "    x = keras.layers.Dense(\n",
        "        units=4096,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    x = keras.layers.Dense(\n",
        "        units=4096,\n",
        "        activation=\"relu\"\n",
        "    )(x)\n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = keras.layers.Dense(\n",
        "        units=num_classes,\n",
        "        activation=\"softmax\"\n",
        "    )(x)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "JdnvHoT74F9E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(train_image_folder)) )"
      ],
      "metadata": {
        "trusted": true,
        "id": "MHZGnesY4F9G"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = model(input_shape=(224, 224, 3), num_classes=len(os.listdir(train_image_folder)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "BMqXIL3r4F9H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "WgLpq9nC4F9I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "YwR9j96e4F9I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, show_shapes = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "t_qds4Lu4F9L"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.1,\n",
        "            patience=3\n",
        "        )\n",
        "    ]"
      ],
      "metadata": {
        "trusted": true,
        "id": "K6tKd2uO4F9M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "4kla4Fb44F9M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "bPoxSvIh4F9N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(\n",
        "#     train_dataset,\n",
        "#     batch_size=1,\n",
        "#     epochs=1,\n",
        "#     validation_data=test_dataset,\n",
        "#     callbacks=callbacks,\n",
        "#     verbose=1\n",
        "# )"
      ],
      "metadata": {
        "id": "X1dVPdGY-Y1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_loss, test_accuracy = model.evaluate(test_dataset, verbose=0)\n",
        "# print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "9LB5QCs74F9O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16 as vgg16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model as models\n",
        "\n",
        "base_model = vgg16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=len(os.listdir(train_image_folder)),\n",
        "    classifier_activation=\"softmax\",\n",
        "    name=\"vgg16\",\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(256, activation = \"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "num_classes = len(os.listdir(train_image_folder))\n",
        "output = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model = models(inputs = base_model.input, outputs = output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "f4aeWgJH6Mni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.utils.plot_model(model, show_shapes = True)"
      ],
      "metadata": {
        "id": "6KPYpmm6WbFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            patience=5,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            factor=0.1,\n",
        "            patience=3\n",
        "        )\n",
        "    ]"
      ],
      "metadata": {
        "id": "vLv7d9v7WemE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "vLmQQsPfZB04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x=train_dataset,\n",
        "    batch_size=32,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    callbacks=callbacks,\n",
        "    validation_data = test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "Zewor8XQXRxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = \"/content/drive/MyDrive/models/vgg\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "model.save(os.path.join(save_dir, \"my_model.keras\"))\n",
        "model.save(\"/content/drive/MyDrive/my_model.keras\")"
      ],
      "metadata": {
        "id": "iu9JC0dVa0Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "0Wp_P0G7ilkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(model.history.history['accuracy'], label = 'train accucracy')\n",
        "plt.plot(model.history.history['val_accuracy'], label = 'value accucracy')\n",
        "plt.title(\"Epochs vs Accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuarcy(sparse categorical loss)\")\n",
        "plt.grid(1)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(model.history.history['loss'], label = 'train loss')\n",
        "plt.plot(model.history.history['val_loss'], label = 'value loss')\n",
        "plt.title(\"Epochs vs Loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.grid(1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d9dmfY95j0x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"loss : {loss}, accuracy : {accuracy}\")"
      ],
      "metadata": {
        "id": "pV4AayQOq6yH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}